{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199af124",
   "metadata": {},
   "source": [
    "\n",
    "# HalfCheetah: Learn a Dynamics Model from Random Rollouts (Then Validate It)\n",
    "\n",
    "**Goal:** In this notebook you'll (1) collect random experience tuples \\((s_t, a_t, r_t, s_{t+1})\\) from `HalfCheetah-v4`, (2) train a neural network to predict **state deltas** \\(\\Delta s = s_{t+1}-s_t\\), and (3) **validate** the model with one-step and multi-step (open-loop) rollouts.\n",
    "\n",
    "This mirrors the first phase of model-based control (e.g., MPPI): learn a model offline, then use it for planning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3392de",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Requirements\n",
    "\n",
    "- Python 3.9+\n",
    "- PyTorch `>= 1.10`\n",
    "- Gymnasium `>= 0.29`\n",
    "- MuJoCo with `HalfCheetah-v4` (install `mujoco` and `gymnasium[mujoco]`)\n",
    "\n",
    "```bash\n",
    "pip install \"gymnasium[mujoco]\" mujoco torch matplotlib\n",
    "```\n",
    "\n",
    "**Try and understand what RunningNormalizer does.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc9e5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mujoco in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (3.3.7)\n",
      "Requirement already satisfied: torch in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: matplotlib in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: gymnasium[mujoco] in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from gymnasium[mujoco]) (2.3.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from gymnasium[mujoco]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from gymnasium[mujoco]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from gymnasium[mujoco]) (0.0.4)\n",
      "Requirement already satisfied: imageio>=2.14.1 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from gymnasium[mujoco]) (2.37.2)\n",
      "Requirement already satisfied: packaging>=23.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from gymnasium[mujoco]) (25.0)\n",
      "Requirement already satisfied: absl-py in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from mujoco) (2.1.0)\n",
      "Requirement already satisfied: etils[epath] in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from mujoco) (1.12.2)\n",
      "Requirement already satisfied: glfw in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from mujoco) (2.10.0)\n",
      "Requirement already satisfied: pyopengl in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from mujoco) (3.1.9)\n",
      "Requirement already satisfied: filelock in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: importlib_resources in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from etils[epath]->mujoco) (6.5.2)\n",
      "Requirement already satisfied: zipp in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from etils[epath]->mujoco) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/juan/anaconda3/envs/mujoco/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"gymnasium[mujoco]\" mujoco torch matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1213bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, random, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "def to_t(x): \n",
    "    return th.as_tensor(x, dtype=th.float32)\n",
    "\n",
    "def fanin_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        bound = 1.0 / math.sqrt(m.weight.size(1))\n",
    "        nn.init.uniform_(m.weight, -bound, +bound)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "class RunningNormalizer:\n",
    "    \"\"\"Feature-wise running mean/std (Welford).\"\"\"\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        self.dim = dim\n",
    "        self.count = 0\n",
    "        self.mean = np.zeros(dim, dtype=np.float64)\n",
    "        self.M2   = np.zeros(dim, dtype=np.float64)\n",
    "        self.eps  = eps\n",
    "\n",
    "    def update(self, x: np.ndarray):\n",
    "        x = np.asarray(x)\n",
    "        if x.ndim == 1: x = x[None, :]\n",
    "        for v in x:\n",
    "            self.count += 1\n",
    "            d = v - self.mean\n",
    "            self.mean += d / self.count\n",
    "            d2 = v - self.mean\n",
    "            self.M2 += d * d2\n",
    "\n",
    "    @property\n",
    "    def var(self):\n",
    "        if self.count < 2: return np.ones(self.dim, dtype=np.float64)\n",
    "        return self.M2 / (self.count - 1 + 1e-12)\n",
    "\n",
    "    @property\n",
    "    def std(self): \n",
    "        return np.sqrt(self.var + self.eps)\n",
    "\n",
    "    def normalize(self, x): return (x - self.mean) / self.std\n",
    "    def denormalize(self, x): return x * self.std + self.mean\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); th.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b5ce5",
   "metadata": {},
   "source": [
    "\n",
    "## Initializing Environment and Figure Out Observation Structure\n",
    "\n",
    "`HalfCheetah-v4` exposes observations as `[qpos[1:], qvel[:]]`. The forward velocity is `qvel[0]`, which sits at index `len(qpos[1:])` inside the observation vector. We'll extract that index for later validation/plots. :::: This is important for planning, if we want to know what each state represents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5de69613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim: 17 act_dim: 6 qvel_start: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set_seed(42)\n",
    "env = gym.make(\"HalfCheetah-v4\")\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "act_low = env.action_space.low\n",
    "act_high = env.action_space.high\n",
    "\n",
    "# Find start index of qvel inside obs = [qpos[1:], qvel[:]]\n",
    "nq = env.unwrapped.model.nq\n",
    "qvel_start = int(nq - 1)\n",
    "print(\"obs_dim:\", obs_dim, \"act_dim:\", act_dim, \"qvel_start:\", qvel_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071b0bb",
   "metadata": {},
   "source": [
    "## ðŸ§© Task 1: Prepare the Replay Buffer\n",
    "**Goal:** Store transitions \\((s_t, a_t, s_{t+1})\\) and return training pairs \\((x, y) = (s_t, a_t, s_{t+1} - s_t)\\).\n",
    "\n",
    "**Instructions:**\n",
    "- Implement `add()` to record transitions.\n",
    "- Add a `sample()` method to randomly sample batch of certain size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08628879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the class and create a class object\n",
    "class Replay:\n",
    "    def __init__(self, obs_dim, act_dim, capacity=300000):\n",
    "        self.obs = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
    "        self.act = np.zeros((capacity, act_dim), dtype=np.float32)\n",
    "        self.nxt = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
    "        self.rew = np.zeros((capacity, 1), dtype=np.float32)\n",
    "        self.term = np.zeros((capacity, 1), dtype=np.float32)\n",
    "        self.ptr = 0; self.size = 0; self.cap = capacity\n",
    "\n",
    "    def add(self, s, a, r, sp, term):\n",
    "        \"\"\"Store one transition (ring buffer).\"\"\"\n",
    "        i = self.ptr % self.cap\n",
    "        self.obs[i]  = s\n",
    "        self.act[i]  = a\n",
    "        self.nxt[i]  = sp\n",
    "        self.rew[i]  = r\n",
    "        self.term[i] = float(term)\n",
    "        self.ptr += 1\n",
    "        if self.size < self.cap:\n",
    "            self.size += 1\n",
    "\n",
    "    def sample(self, batch, as_pairs=True, rng=None):\n",
    "        \"\"\"\n",
    "        Random sample.\n",
    "        If as_pairs=True, returns (X, Y) where:\n",
    "          X = concat([s, a])\n",
    "          Y = (s_next - s)   # state delta\n",
    "        Otherwise returns raw (s, a, r, sp, term).\n",
    "        \"\"\"\n",
    "        if self.size == 0:\n",
    "            raise ValueError(\"Replay is empty.\")\n",
    "        rng = np.random.default_rng() if rng is None else rng\n",
    "        idx = rng.integers(0, self.size, size=batch)\n",
    "\n",
    "        s  = self.obs[idx]\n",
    "        a  = self.act[idx]\n",
    "        sp = self.nxt[idx]\n",
    "        r  = self.rew[idx]\n",
    "        d  = self.term[idx]\n",
    "\n",
    "        if as_pairs:\n",
    "            X = np.concatenate([s, a], axis=1).astype(np.float32, copy=False)\n",
    "            Y = (sp - s).astype(np.float32, copy=False)\n",
    "            return X, Y\n",
    "        else:\n",
    "            return s, a, r, sp, d\n",
    "\n",
    "replay = Replay(obs_dim, act_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374692ef",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2. Collect Random Rollouts\n",
    "\n",
    "- Gather random actions for a number of steps to create our training dataset. Collect data for 100000 steps. \n",
    "- Call the function and fill the replay buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d7b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_random(env, replay, steps=100_000, seed=42):\n",
    "    \"\"\"\n",
    "    Roll out random actions for `steps` env steps and push transitions into `replay`.\n",
    "\n",
    "    Stores (s, a, r, s', done) where done = terminated OR truncated.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "\n",
    "    low, high = env.action_space.low, env.action_space.high\n",
    "    n = 0\n",
    "    ep_returns, ep_len, ret = [], 0, 0.0\n",
    "\n",
    "    while n < steps:\n",
    "        # random continuous action in valid bounds\n",
    "        a = rng.uniform(low, high).astype(np.float32)\n",
    "\n",
    "        nxt, r, terminated, truncated, _ = env.step(a)\n",
    "        done = bool(terminated or truncated)\n",
    "\n",
    "        replay.add(obs, a, r, nxt, done)\n",
    "\n",
    "        # bookkeeping\n",
    "        ret += float(r); ep_len += 1; n += 1\n",
    "\n",
    "        if done:\n",
    "            ep_returns.append(ret)\n",
    "            ret, ep_len = 0.0, 0\n",
    "            obs, _ = env.reset()\n",
    "        else:\n",
    "            obs = nxt\n",
    "\n",
    "    return {\n",
    "        \"steps\": n,\n",
    "        \"episodes\": len(ep_returns),\n",
    "        \"avg_return\": float(np.mean(ep_returns)) if ep_returns else 0.0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7689c7f",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3. Update normalizers from the collected random data in the replay buffer\n",
    "\n",
    "We normalize inputs (`[s,a]`) and targets (`Î”s = s' - s`) for stable training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39332ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay is empty â€” collect data first.\n",
      "Normalizers ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obs_norm = RunningNormalizer(obs_dim)\n",
    "inp_norm = RunningNormalizer(obs_dim + act_dim)\n",
    "targ_norm = RunningNormalizer(obs_dim)\n",
    "\n",
    "# write the function to update the normalizers from the data collected in the buffer\n",
    "def update_normalizers_from_buffer(replay, chunk=65_536):\n",
    "    \"\"\"\n",
    "    Fit the running normalizers from transitions stored in `replay`.\n",
    "    Uses chunking to avoid large temporary allocations.\n",
    "    \"\"\"\n",
    "    n = replay.size\n",
    "    if n == 0:\n",
    "        print(\"Replay is empty â€” collect data first.\")\n",
    "        return\n",
    "\n",
    "    for start in range(0, n, chunk):\n",
    "        sl = slice(start, min(start + chunk, n))\n",
    "        s  = replay.obs[sl]           # (B, obs_dim)\n",
    "        a  = replay.act[sl]           # (B, act_dim)\n",
    "        sp = replay.nxt[sl]           # (B, obs_dim)\n",
    "\n",
    "        X = np.concatenate([s, a], axis=1)   # inputs [s, a]\n",
    "        Y = sp - s                            # targets Î”s\n",
    "\n",
    "        obs_norm.update(s)\n",
    "        obs_norm.update(sp)\n",
    "        inp_norm.update(X)\n",
    "        targ_norm.update(Y)\n",
    "\n",
    "update_normalizers_from_buffer(replay)\n",
    "print(\"Normalizers ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566164a4",
   "metadata": {},
   "source": [
    "\n",
    "## Defining the Neural Dynamics Model\n",
    "\n",
    "We predict **normalized** `Î”s` from **normalized** `[s, a]`.\n",
    "NN parameters: \n",
    "\n",
    "- initialize a deterministic NN with a ExponentialLR sceduler( that decays the learning rate with epoch)\n",
    "- width = 200, depth = 3, lr = 1e-3, weight_decay - 1e-5, gamma for scheduler = 0.8\n",
    "- These are a starting point but not the best parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Model -----\n",
    "import math, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "EPS = 1e-8\n",
    "\n",
    "def fanin_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class DetMLP(nn.Module):\n",
    "    \"\"\"Predicts Î”state deterministically from normalized [s,a].\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, width=200, depth=3):\n",
    "        super().__init__()\n",
    "        layers, last = [], in_dim\n",
    "        for _ in range(depth):\n",
    "            layers += [nn.Linear(last, width), nn.ReLU()]\n",
    "            last = width\n",
    "        layers += [nn.Linear(last, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.apply(fanin_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# dims from your env\n",
    "in_dim  = obs_dim + act_dim\n",
    "out_dim = obs_dim\n",
    "\n",
    "model = DetMLP(in_dim, out_dim, width=200, depth=3).to(DEVICE)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(opt, gamma=0.8)\n",
    "\n",
    "# ----- Normalization helpers (use your RunningNormalizer stats) -----\n",
    "def _mean_std(n):\n",
    "    # Works with either torch/np attributes on your RunningNormalizer\n",
    "    m = getattr(n, \"mean\", None); s = getattr(n, \"std\", None)\n",
    "    if m is None or s is None:      # if class exposes .mu/.sigma\n",
    "        m = getattr(n, \"mu\"); s = getattr(n, \"sigma\")\n",
    "    return np.asarray(m), np.asarray(s)\n",
    "\n",
    "_inp_mu, _inp_std   = _mean_std(inp_norm)\n",
    "_targ_mu, _targ_std = _mean_std(targ_norm)\n",
    "\n",
    "def norm_inputs(X):\n",
    "    return (X - _inp_mu) / (np.maximum(_inp_std, EPS))\n",
    "\n",
    "def norm_targets(Y):\n",
    "    return (Y - _targ_mu) / (np.maximum(_targ_std, EPS))\n",
    "\n",
    "def denorm_targets(Yn):\n",
    "    return Yn * _targ_std + _targ_mu\n",
    "\n",
    "# ----- One-shot trainer -----\n",
    "def train_dynamics(model, replay, epochs=25, batch=1024, iters_per_epoch=200):\n",
    "    model.train()\n",
    "    mse = nn.MSELoss()\n",
    "    for ep in range(epochs):\n",
    "        running = 0.0\n",
    "        for _ in range(iters_per_epoch):\n",
    "            X, Y = replay.sample(batch)          # X=[s,a], Y=Î”s (both np.float32)\n",
    "            Xn = norm_inputs(X).astype(np.float32, copy=False)\n",
    "            Yn = norm_targets(Y).astype(np.float32, copy=False)\n",
    "\n",
    "            Xt = torch.from_numpy(Xn).to(DEVICE)\n",
    "            Yt = torch.from_numpy(Yn).to(DEVICE)\n",
    "\n",
    "            pred = model(Xt)\n",
    "            loss = mse(pred, Yt)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "        scheduler.step()\n",
    "        print(f\"epoch {ep+1:02d}  lr={scheduler.get_last_lr()[0]:.3e}  \"\n",
    "              f\"train_mse={running/iters_per_epoch:.6f}\")\n",
    "\n",
    "# ----- Convenience: predict next state with the trained model -----\n",
    "@torch.no_grad()\n",
    "def one_step_predict(s, a):\n",
    "    \"\"\"\n",
    "    s: (obs_dim,) np\n",
    "    a: (act_dim,) np\n",
    "    returns s_next_pred (obs_dim,) in original (unnormalized) space\n",
    "    \"\"\"\n",
    "    X = np.concatenate([s[None, :], a[None, :]], axis=1).astype(np.float32)\n",
    "    Xn = norm_inputs(X).astype(np.float32)\n",
    "    yhat_n = model(torch.from_numpy(Xn).to(DEVICE)).cpu().numpy()[0]\n",
    "    dS = denorm_targets(yhat_n)\n",
    "    return (s + dS).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3db88",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4. Train the Model\n",
    "\n",
    "We minimize MSE between predicted normalized `Î”s` and target normalized `Î”s`.\n",
    "\n",
    "- Train in batches, keep the batch size 256\n",
    "- Use a learning rate scheduler that decays the learning rate as training progresses. You may use the pytorch utility. See how the learning rate decays with each epoch. \n",
    "- Train for 30 epochs and plot the training curve. Loss vs epoch. \n",
    "- Find the best parameters(defined in the previous block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a39c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, replay, epochs=30, batch_size=256):\n",
    "    pass\n",
    "    # return losses\n",
    "\n",
    "# losses = train_model(model, replay, epochs=10, batch_size=64)\n",
    "# plt.figure()\n",
    "# plt.plot(losses)\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"MSE (normalized Î”s)\")\n",
    "# plt.title(\"Model Training Loss\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1c7c0",
   "metadata": {},
   "source": [
    "## Task 5. Validate your model: One-Step and Multi-Step Prediction Error\n",
    "\n",
    "- Evaluate your trained model on a held-out set of random transitions.\n",
    "Generate a batch of unseen samples, predict the next-state delta, and compute the one-step MSE.\n",
    "\n",
    "- Repeat with open-loop rollouts of length k.\n",
    "Drive both the real environment and the model with the same action sequence, then report how prediction error grows across steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efe4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a173d",
   "metadata": {},
   "source": [
    "\n",
    "## Task 6. Visualize Rollout Trajectories\n",
    "\n",
    "**Setup**\n",
    "Call model.eval() so gradients stay off.\n",
    "Reset the env with the provided seed; keep a copy of the initial observation.\n",
    "\n",
    "\n",
    "**Choose actions**\n",
    "Pre-sample k actions from env.action_space.sample() so the real system and the model rollout see the same sequence.\n",
    "\n",
    "**Roll forward**\n",
    "For each action:\n",
    "Step the real env (env.step(a)), append the new observation.\n",
    "For the model path:\n",
    "Build [s_model, a], normalize via inp_norm.normalize, turn into a tensor with to_t.\n",
    "Run the network, de-normalize with targ_norm.denormalize, add to the last model state, append.\n",
    "Stop early if the env terminates or truncates.\n",
    "\n",
    "**Plot**\n",
    "Plot the real trajectory as one line, model trajectory as another.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aebb7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_rollout(env, model, k=50, dims=(0, 5, 10), seed=2025):\n",
    "    pass\n",
    "\n",
    "# Uncomment to visualize\n",
    "dims = list(range(1, 17))\n",
    "# visualize_rollout(env, model, k=50, dims=dims)#(qvel_start, qvel_start+1, qvel_start+2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f48f2",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Answer the questions : \n",
    "\n",
    "1. How good is your model? \n",
    "2. Is this training enough for planning, or do we need continual training?\n",
    "3. How is this system different from the mountain car problem? Why can't we learn this in one episode? \n",
    "4. Why do we use a runningnormalizer instead of a static normalizer? Think about the nature of the algorithm taught in class. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
